{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_io(i, res_dict): # a function simulating IO, user input, etc. (no computation)\n",
    "    print(f'function {i} started at {time.ctime()}')\n",
    "    time.sleep(2)\n",
    "    res = i*2\n",
    "    res_dict[i] = res\n",
    "    print(f'function {i} finished at {time.ctime()}')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 0 started at Mon Jul  1 20:16:53 2019\n",
      "function 0 finished at Mon Jul  1 20:16:55 2019\n",
      "function 1 started at Mon Jul  1 20:16:55 2019\n",
      "function 1 finished at Mon Jul  1 20:16:57 2019\n",
      "function 2 started at Mon Jul  1 20:16:57 2019\n",
      "function 2 finished at Mon Jul  1 20:16:59 2019\n",
      "function 3 started at Mon Jul  1 20:16:59 2019\n",
      "function 3 finished at Mon Jul  1 20:17:01 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 2, 2: 4, 3: 6}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = {}\n",
    "[long_io(i, res) for i in range(4)]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_comp(i, res_dict): # a function involving heavy computation\n",
    "    print(f'function {i} started at {time.ctime()}')\n",
    "    x = i\n",
    "    for y in range(5000000):\n",
    "        if x % 2 == 0:\n",
    "            x = (x-y)**2\n",
    "        else:\n",
    "            x = (x+y)**0.5\n",
    "    res_dict[i] = x\n",
    "    print(f'function {i} finished at {time.ctime()}')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 0 started at Mon Jul  1 20:17:01 2019\n",
      "function 0 finished at Mon Jul  1 20:17:03 2019\n",
      "function 1 started at Mon Jul  1 20:17:03 2019\n",
      "function 1 finished at Mon Jul  1 20:17:06 2019\n",
      "function 2 started at Mon Jul  1 20:17:06 2019\n",
      "function 2 finished at Mon Jul  1 20:17:08 2019\n",
      "function 3 started at Mon Jul  1 20:17:08 2019\n",
      "function 3 finished at Mon Jul  1 20:17:10 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 2236.5678097446853,\n",
       " 1: 2236.5678097446853,\n",
       " 2: 2236.5678097446853,\n",
       " 3: 2236.5678097446853}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = {}\n",
    "[long_comp(i, res) for i in range(4)]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time intensive functions can be either CPU-limited (calculations) or limited by other factors (such as IO, network response times, user interactions). For both cases, test functions are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 0 started at Mon Jul  1 20:17:10 2019\n",
      "function 1 started at Mon Jul  1 20:17:10 2019\n",
      "function 2 started at Mon Jul  1 20:17:10 2019\n",
      "function 3 started at Mon Jul  1 20:17:10 2019\n",
      "all threads started at Mon Jul  1 20:17:10 2019\n",
      "function 0 finished at Mon Jul  1 20:17:12 2019\n",
      "function 1 finished at Mon Jul  1 20:17:12 2019\n",
      "function 2 finished at Mon Jul  1 20:17:12 2019\n",
      "function 3 finished at Mon Jul  1 20:17:12 2019\n",
      "all threads finished at Mon Jul  1 20:17:12 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 2, 2: 4, 3: 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-computational limited function\n",
    "threads = []\n",
    "res = {}\n",
    "for i in range(4):\n",
    "    threads.append(threading.Thread(target=long_io, args=(i,res)))\n",
    "    threads[i].start()\n",
    "print(f'all threads started at {time.ctime()}')\n",
    "for i in range(4):\n",
    "    threads[i].join()\n",
    "print(f'all threads finished at {time.ctime()}')\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Multithreading, executing all 4 functions take the same time as executing a single function.\n",
    "\n",
    "\n",
    "Threads use the same memory space as the main process, thus one could use data structures like dictionaries to pass information from and to the threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 0 started at Mon Jul  1 20:17:12 2019\n",
      "function 1 started at Mon Jul  1 20:17:12 2019\n",
      "function 2 started at Mon Jul  1 20:17:13 2019\n",
      "function 3 started at Mon Jul  1 20:17:13 2019\n",
      "all threads started at Mon Jul  1 20:17:13 2019\n",
      "function 0 finished at Mon Jul  1 20:17:21 2019\n",
      "function 3 finished at Mon Jul  1 20:17:21 2019\n",
      "function 2 finished at Mon Jul  1 20:17:21 2019\n",
      "function 1 finished at Mon Jul  1 20:17:22 2019\n",
      "all threads finished at Mon Jul  1 20:17:22 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 2236.5678097446853,\n",
       " 3: 2236.5678097446853,\n",
       " 2: 2236.5678097446853,\n",
       " 1: 2236.5678097446853}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computational limited function\n",
    "threads = []\n",
    "res = {}\n",
    "for i in range(4):\n",
    "    threads.append(threading.Thread(target=long_comp, args=(i,res)))\n",
    "    threads[i].start()\n",
    "print(f'all threads started at {time.ctime()}')\n",
    "for i in range(4):\n",
    "    threads[i].join()\n",
    "print(f'all threads finished at {time.ctime()}')\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the computational intensive function, running 4 instances as thread takes nearly 4 times as long as running a single instance.\n",
    "This is true even for multiple processors.\n",
    "\n",
    "Reason: The Global Interpreter Lock (GIL) in CPython allows only one CPU access at a time for one process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 1 started at Mon Jul  1 20:17:22 2019\n",
      "function 0 started at Mon Jul  1 20:17:22 2019\n",
      "function 3 started at Mon Jul  1 20:17:22 2019\n",
      "function 2 started at Mon Jul  1 20:17:22 2019\n",
      "all processes started at Mon Jul  1 20:17:22 2019\n",
      "function 0 finished at Mon Jul  1 20:17:24 2019\n",
      "function 1 finished at Mon Jul  1 20:17:24 2019\n",
      "function 3 finished at Mon Jul  1 20:17:24 2019\n",
      "function 2 finished at Mon Jul  1 20:17:24 2019\n",
      "all processes finished at Mon Jul  1 20:17:24 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-computational limited function\n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "processes = []\n",
    "res = {}\n",
    "for i in range(4):\n",
    "    processes.append(pool.apply_async(long_io, args=(i,res)))\n",
    "print(f'all processes started at {time.ctime()}')\n",
    "pool.close() # close pool so that it does not accept further submissions\n",
    "pool.join() # wait until all processes are finished\n",
    "print(f'all processes finished at {time.ctime()}')\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the dictionary passed as function parameter is not updated by the processes (in contrast to the threads shown above). This is because the spawned processes do not share memory with each other / the main process.\n",
    "\n",
    "The return value of the functions can be obtained using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[process.get() for process in processes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function 0 started at Mon Jul  1 20:17:24 2019\n",
      "function 1 started at Mon Jul  1 20:17:24 2019\n",
      "function 2 started at Mon Jul  1 20:17:24 2019\n",
      "function 3 started at Mon Jul  1 20:17:24 2019\n",
      "all processes started at Mon Jul  1 20:17:24 2019\n",
      "function 0 finished at Mon Jul  1 20:17:27 2019\n",
      "function 1 finished at Mon Jul  1 20:17:27 2019\n",
      "function 3 finished at Mon Jul  1 20:17:27 2019\n",
      "function 2 finished at Mon Jul  1 20:17:27 2019\n",
      "all processes finished at Mon Jul  1 20:17:27 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computational limited function\n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "processes = []\n",
    "res = {}\n",
    "for i in range(4):\n",
    "    processes.append(pool.apply_async(long_comp, args=(i,res)))\n",
    "print(f'all processes started at {time.ctime()}')\n",
    "pool.close() # close pool so that it does not accept further submissions\n",
    "pool.join() # wait until all processes are finished\n",
    "print(f'all processes finished at {time.ctime()}')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2236.5678097446853,\n",
       " 1: 2236.5678097446853,\n",
       " 2: 2236.5678097446853,\n",
       " 3: 2236.5678097446853}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i: process.get() for i, process in enumerate(processes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Multiprocessing, the instances of the computational intensive function were exectuted in parallel (here on 4 cores), resulting in the same calculation time as for a single instance.\n",
    "\n",
    "\n",
    "Different processes do not share memory with each other and the main process (in contrast to threads). This may sound like a disadvantage compared to threads, but is actually in most cases an advantage:\n",
    "\n",
    "* The GIL is avoided using Multiprocessing (the reason for GIL is to avoid memory conflicts, which could not happen here), allowing parallelization of computational-intensive functions on multiple CPU cores.\n",
    "* Pure functions, where all input is given as function arguments and all output is in the return value, work fine with multiprocessing.\n",
    "* Side-effects due to global variables or mutable data types are avoided. The code is enforced to be cleaner and more modular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "* For non-calculation bound processes, like IO, user interactions, network responses, use Threading because it is light-weight and creates less overhead.\n",
    "* For calculation-bound processes, use Multiprocessing. In Python, there is no benefit using Multithreading in this case.\n",
    "\n",
    "More information is given here:\n",
    "https://medium.com/@bfortuner/python-multithreading-vs-multiprocessing-73072ce5600b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
